sh{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nassy\\Anaconda3\\envs\\PyTorch\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\nassy\\Anaconda3\\envs\\PyTorch\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\nassy\\Anaconda3\\envs\\PyTorch\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\nassy\\Anaconda3\\envs\\PyTorch\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\nassy\\Anaconda3\\envs\\PyTorch\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\nassy\\Anaconda3\\envs\\PyTorch\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\nassy\\Anaconda3\\envs\\PyTorch\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\nassy\\Anaconda3\\envs\\PyTorch\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\nassy\\Anaconda3\\envs\\PyTorch\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\nassy\\Anaconda3\\envs\\PyTorch\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\nassy\\Anaconda3\\envs\\PyTorch\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\nassy\\Anaconda3\\envs\\PyTorch\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import CamembertModel, CamembertTokenizer, CamembertConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    pass\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_json(\"../data/train.json\")\n",
    "valid_df = pd.read_json(\"../data/valid.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = CamembertTokenizer.from_pretrained(\"illuin/lepetit\")\n",
    "\n",
    "config = CamembertConfig(\n",
    "    vocab_size = tokenizer.vocab_size,\n",
    "    hidden_size = 256,\n",
    "    num_hidden_layers = 4,\n",
    "    num_attention_heads = 4)\n",
    "\n",
    "question_model = CamembertModel(config = config)\n",
    "context_model = CamembertModel(config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-724421917ed4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'paragraphs'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'paragraphs'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'context'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m512\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m             \u001b[0mtrain_df\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(len(train_df)):\n",
    "    for j in range(len(train_df.iloc[i]['data']['paragraphs'])):\n",
    "        if len(tokenizer.encode(df.iloc[i]['data']['paragraphs'][j]['context'])) > 512:\n",
    "            train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "question_model = CamembertModel.from_pretrained(\"illuin/lepetit\", return_dict = True)\n",
    "context_model = CamembertModel.from_pretrained(\"illuin/lepetit\", return_dict = True)\n",
    "\n",
    "tokenizer = CamembertTokenizer.from_pretrained(\"illuin/lepetit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_context(df):\n",
    "    contexts = []\n",
    "    for i in range(len(df)):\n",
    "        for j in range(len(df.iloc[i]['data']['paragraphs'])):\n",
    "            contexts.append(tokenizer.encode(df.iloc[i]['data']['paragraphs'][j]['context']))\n",
    "            \n",
    "    return contexts\n",
    "\n",
    "# Create a list of documents\n",
    "train_contexts = create_context(train_df)\n",
    "valid_contexts = create_context(valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_qa(df):\n",
    "    questions, answers = [], []\n",
    "    id_to_ans = {}\n",
    "    for i in range(len(df)):\n",
    "        for j in range(len(df.iloc[i]['data']['paragraphs'])):\n",
    "            for k in range(len(df.iloc[i]['data']['paragraphs'][j]['qas'])):\n",
    "                questions.append(tokenizer.encode(df.iloc[i]['data']['paragraphs'][j]['qas'][k]['question']))\n",
    "                answers.append((i,j))\n",
    "            id_to_ans[(i,j)] = len(id_to_ans)\n",
    "            \n",
    "    return questions, answers, id_to_ans\n",
    "\n",
    "train_q, train_a, train_id_to_ans = create_qa(train_df)\n",
    "valid_q, valid_a, valid_id_to_ans = create_qa(valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.get_vocab()['<pad>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.get_vocab()['</s>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class DatasetFQuAD(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, questions, answers, id_to_ans, contexts):\n",
    "        self.questions = questions\n",
    "        self.answers = answers\n",
    "        self.id_to_ans = id_to_ans\n",
    "        self.contexts = contexts\n",
    "        \n",
    "        self.q_len = 128\n",
    "        self.c_len = 512\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        question = self.questions[index]\n",
    "        good_index = self.id_to_ans[self.answers[index]]\n",
    "        \n",
    "        right_context = random.random() >= 0.5\n",
    "        \n",
    "        if right_context:\n",
    "            context = self.contexts[good_index]\n",
    "            target = torch.tensor(1)\n",
    "        else:\n",
    "            context = random.choice(self.contexts[:good_index]+self.contexts[good_index + 1:])\n",
    "            target = torch.tensor(-1)\n",
    "                        \n",
    "        if len(question) > self.q_len:\n",
    "            question = question[:self.q_len]\n",
    "            question[-1] = 6\n",
    "        else:\n",
    "            question += [1] * (self.q_len - len(question))\n",
    "            \n",
    "        if len(context) > self.c_len:\n",
    "            context = context[:self.c_len+1]\n",
    "            context[-1] = 1\n",
    "            context[-2] = 6\n",
    "            print(\"long c\")\n",
    "        else:\n",
    "            context += [1] * (self.c_len - len(context))\n",
    "            \n",
    "        #print(context)\n",
    "                        \n",
    "        return torch.tensor(question), torch.tensor(context), target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.questions)\n",
    "    \n",
    "train_dataset = DatasetFQuAD(train_q, train_a, train_id_to_ans, train_contexts)\n",
    "valid_dataset = DatasetFQuAD(valid_q, valid_a, valid_id_to_ans, valid_contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset = train_dataset,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True,\n",
    "    )\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    dataset = valid_dataset,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, question_model, context_model):\n",
    "        super(FullModel, self).__init__()\n",
    "        \n",
    "        self.question_model = question_model\n",
    "        self.context_model = context_model\n",
    "        \n",
    "        self.question_linear = nn.Linear(256 * 128, 1024)\n",
    "        self.context_linear = nn.Linear(256 * 512, 1024)\n",
    "        \n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        \n",
    "        questions, contexts = inputs[0], inputs[1]\n",
    "        \n",
    "        q_out = self.question_model(questions, return_dict = True)\n",
    "        c_out = self.context_model(contexts, return_dict = True)\n",
    "                        \n",
    "        linear_q = self.question_linear(q_out[\"last_hidden_state\"].view(1, -1))\n",
    "        linear_c = self.context_linear(c_out[\"last_hidden_state\"].view(1, -1))\n",
    "                \n",
    "        return linear_q, linear_c\n",
    "    \n",
    "model = FullModel(question_model, context_model)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_loss = nn.CosineEmbeddingLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train(model, loader, f_loss, optimizer, device):\n",
    "\n",
    "    # We enter train mode. This is useless for the linear model\n",
    "    # but is important for layers such as dropout, batchnorm, ...\n",
    "    model.train()\n",
    "        \n",
    "    tot_loss = 0\n",
    "    N = len(train_dataset)\n",
    "        \n",
    "    iterator = tqdm(enumerate(loader))\n",
    "\n",
    "    for i, (questions, contexts, targets) in iterator:\n",
    "        \n",
    "        print(contexts.size())\n",
    "        inputs, targets = [questions.to(device), contexts.to(device)], targets.to(device)\n",
    "\n",
    "        # Compute the forward pass through the network up to the loss\n",
    "        q_outputs, c_outputs = model(inputs)\n",
    "        \n",
    "        loss = f_loss(q_outputs, c_outputs, targets)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        tot_loss += inputs[0].shape[0] * f_loss(q_outputs, c_outputs, targets).item()\n",
    "        \n",
    "        iterator.set_description(\"Current training loss : {: .3f}\".format(tot_loss/(i +1)))\n",
    "\n",
    "    return tot_loss/N\n",
    "\n",
    "# An example of calling train to learn over 10 epochs of the training set\n",
    "for i in range(10):\n",
    "    loss = train(model, train_loader, f_loss, optimizer, device)\n",
    "    print('Loss : {:2.4f}\\r'.format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
